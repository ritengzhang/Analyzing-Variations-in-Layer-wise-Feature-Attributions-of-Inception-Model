{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12878,"status":"ok","timestamp":1698680684939,"user":{"displayName":"张日腾","userId":"15474554812672166345"},"user_tz":240},"id":"BwxjuWX_Z-hD","outputId":"d25227bf-b436-4793-f4d6-119c321c2de7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4TuItTJELaX","executionInfo":{"status":"ok","timestamp":1698680692238,"user_tz":240,"elapsed":7302,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"f4300942-514d-4239-82dc-a5462dccd6e6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting captum\n","  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n","Installing collected packages: captum\n","Successfully installed captum-0.6.0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"v1WCo6P2V9Rj","executionInfo":{"status":"ok","timestamp":1698680698502,"user_tz":240,"elapsed":6269,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from captum.attr import LayerIntegratedGradients\n","from captum.attr import LayerConductance\n","from captum.attr import LayerDeepLift\n","import pickle\n","import os\n","import csv"]},{"cell_type":"code","source":["MODEL_STRUCTURE = \"Naive inception structure1\"\n","SAVE_PATH_ATT = '/content/drive/My Drive/2023 InterpretingNN/code/attribution saved/'+MODEL_STRUCTURE\n","SAVE_PATH_MODEL = '/content/drive/My Drive/2023 InterpretingNN/code/model saved/'+MODEL_STRUCTURE\n","method_names = [\"LayerConductance\", \"LayerIntegratedGradients\", \"LayerDeepLift\"]"],"metadata":{"id":"iGIJ829bgvE-","executionInfo":{"status":"ok","timestamp":1698680698502,"user_tz":240,"elapsed":11,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Model structure defination"],"metadata":{"id":"3PEfJs6TqkYl"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"RBL4NJNdWZlo","executionInfo":{"status":"ok","timestamp":1698680698503,"user_tz":240,"elapsed":11,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"outputs":[],"source":["class NaiveInception(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(NaiveInception, self).__init__()\n","\n","        self.conv1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n","        self.conv1x1_3x3 = nn.Sequential(\n","            nn.Conv2d(in_channels, 8, kernel_size=1),\n","            nn.Conv2d(8, 16, kernel_size=3, padding=1)\n","        )\n","        self.conv1x1_5x5 = nn.Sequential(\n","            nn.Conv2d(in_channels, 8, kernel_size=1),\n","            nn.Conv2d(8, 16, kernel_size=5, padding=2)\n","        )\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(38416, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, num_classes)  # Number of output classes\n","        )\n","\n","    def forward(self, x):\n","        x1 = self.conv1x1(x)\n","        x2 = self.conv1x1_3x3(x)\n","        x3 = self.conv1x1_5x5(x)\n","        x4 = self.pool(x)\n","        x = torch.cat((x1, x2, x3, x4), dim=1)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"markdown","source":["model initialization function"],"metadata":{"id":"Zr8qWNsaOZZG"}},{"cell_type":"code","source":["def init_weights(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","        nn.init.normal_(m.weight, mean=0, std=0.01)\n","        nn.init.constant_(m.bias, 0)"],"metadata":{"id":"UhHjlwbtOY1f","executionInfo":{"status":"ok","timestamp":1698680698503,"user_tz":240,"elapsed":11,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Train all models and record attributions"],"metadata":{"id":"XXZkt8qbqf0O"}},{"cell_type":"markdown","source":["get train process"],"metadata":{"id":"QzIPgKX7rbum"}},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":140,"status":"ok","timestamp":1698680737445,"user":{"displayName":"张日腾","userId":"15474554812672166345"},"user_tz":240},"id":"OwGcAozxTBPX"},"outputs":[],"source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_subset = datasets.MNIST('.', train=True, download=True, transform=transform)\n","test_subset = datasets.MNIST('.', train=False, download=True, transform=transform)\n","\n","# Define the size of the random subsets\n","train_indices = torch.randperm(len(train_subset))[:30000]\n","test_indices = torch.randperm(len(test_subset))[:1000]\n","\n","train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n","test_loader = torch.utils.data.DataLoader(test_subset, batch_size=128, sampler=torch.utils.data.SequentialSampler(test_indices))"]},{"cell_type":"markdown","source":["train and eval function"],"metadata":{"id":"tgrdsZx2reqY"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"J2MutHefenjn","executionInfo":{"status":"ok","timestamp":1698680739729,"user_tz":240,"elapsed":3,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"outputs":[],"source":["def train(epoch):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = output.max(1)\n","        total += target.size(0)\n","        correct += predicted.eq(target).sum().item()\n","\n","    train_accuracy = 100. * correct / total\n","    print(f\"Epoch {epoch}: Train Loss = {train_loss / len(train_loader):.4f}, Train Accuracy = {train_accuracy:.2f}%\")\n","\n","\n","def test(epoch):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            test_loss += loss.item()\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","    test_accuracy = 100. * correct / total\n","    print(f\"Epoch {epoch}: Test Loss = {test_loss / len(test_loader):.4f}, Test Accuracy = {test_accuracy:.2f}%\")"]},{"cell_type":"markdown","source":["write attribution information into a csv file"],"metadata":{"id":"n30GTvoXsPCO"}},{"cell_type":"code","source":["def write_dict_to_csv_row(data_dict, filename):\n","    # Check if the file exists, and if not, create it\n","    try:\n","        with open(filename, 'r', newline='') as file:\n","            # If the file exists, check if it's empty\n","            if len(file.read()) == 0:\n","                # If the file is empty, write the header\n","                write_header = True\n","            else:\n","                write_header = False\n","    except FileNotFoundError:\n","        # If the file doesn't exist, create it and write the header\n","        write_header = True\n","\n","    with open(filename, 'a', newline='') as file:\n","        fieldnames = data_dict.keys()\n","        writer = csv.DictWriter(file, fieldnames=fieldnames)\n","\n","        if write_header:\n","            writer.writeheader()\n","\n","        writer.writerow(data_dict)"],"metadata":{"id":"mB5HZWb1s0b2","executionInfo":{"status":"ok","timestamp":1698680741703,"user_tz":240,"elapsed":266,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["functions for calculate attribution"],"metadata":{"id":"oaOM2lSHr84W"}},{"cell_type":"code","source":["def calculate_attribution_one_layer(model, layer, input_data, target_class, method):\n","    methods = {\"LayerConductance\": LayerConductance, \"LayerIntegratedGradients\": LayerIntegratedGradients, \"LayerDeepLift\": LayerDeepLift}\n","    using_function = methods[method](model, layer)\n","    attribution = using_function.attribute(input_data, target=target_class)\n","\n","    return attribution"],"metadata":{"id":"bqNNcDVNEATu","executionInfo":{"status":"ok","timestamp":1698680752888,"user_tz":240,"elapsed":134,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def get_all_attributions_one_input(model, input_data, target_class, method):\n","    all_attributions = {}\n","    for name, layer in model.named_children():\n","      print(name)\n","      all_attributions[layer] = []\n","      layer_attributions=calculate_attribution_one_layer(model, layer, input_data, target_class, method)\n","      all_attributions[layer]=layer_attributions\n","    return all_attributions"],"metadata":{"id":"5HyQeJvGEBve","executionInfo":{"status":"ok","timestamp":1698680754171,"user_tz":240,"elapsed":133,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def calculate_and_save_attributions(model, model_index, sample_input, target_class, method_names, SAVE_PATH, MODEL_STRUCTURE):\n","    # Ensure sample_input has gradients\n","    sample_input.requires_grad_()\n","\n","    # Set device for model and input tensor\n","    device = torch.device(\"cpu\")\n","    sample_input = sample_input.to(device)\n","    model.to(device)\n","\n","    # Calculate and print importance scores for each layer and neuron\n","    for method in method_names:\n","        print(method)\n","        attributions = get_all_attributions_one_input(model, sample_input, target_class, method=method)\n","        attribution_sum = 0\n","\n","        for i in attributions:\n","            attribution_sum = attribution_sum + attributions[i].sum().item()\n","\n","        for i in attributions:\n","            a = attributions[i].sum().item() / attribution_sum\n","            formatted_number = f\"{a:.2f}\"\n","            print(formatted_number)\n","            print(attributions[i].shape)\n","            print()\n","\n","            file_name = MODEL_STRUCTURE + model_index + method + 'attributions.pkl'\n","            file_path = os.path.join(SAVE_PATH_ATT, file_name)\n","\n","            # Save the dictionary to a Pickle file\n","            '''with open(file_path, 'wb') as file:\n","                pickle.dump(attributions, file)'''\n","\n","        print(\"\\n\\n\")\n","\n","# Example usage:\n","#sample_input, target_class = next(iter(test_loader))\n","#calculate_and_save_attributions(model, model_index, sample_input, target_class, method_names, SAVE_PATH_ATT, MODEL_STRUCTURE)\n"],"metadata":{"id":"P59jSsIhkWtk","executionInfo":{"status":"ok","timestamp":1698680759050,"user_tz":240,"elapsed":165,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["train, save, and recored attribution info of models"],"metadata":{"id":"qk1DF9SfsG--"}},{"cell_type":"code","source":["for i in range(5):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    in_channels = 1  # Input channels (e.g., for RGB images)\n","    num_classes = 10  # Number of classes in your classification task\n","\n","    model = NaiveInception(in_channels, num_classes)\n","    model.apply(init_weights)\n","    model = model.to(device)\n","    optimizer = optim.SGD(model.parameters(), lr=0.01)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    for epoch in range(3):\n","      train(epoch)\n","      test(epoch)\n","    model_index=\"test\"+str(i)\n","    sample_input, target_class=None, None\n","    for batch_idx, (data, target) in enumerate(test_loader):\n","      sample_input, target_class = data, target\n","      break\n","    calculate_and_save_attributions(model, model_index, sample_input, target_class, method_names, SAVE_PATH_ATT, MODEL_STRUCTURE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEwX5Pk5f3Ru","executionInfo":{"status":"ok","timestamp":1698681284211,"user_tz":240,"elapsed":523055,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"5b55b176-b604-4029-b96e-7dc6d8a95c60"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: Train Loss = 1.2565, Train Accuracy = 68.41%\n","Epoch 0: Test Loss = 0.6008, Test Accuracy = 82.30%\n","Epoch 1: Train Loss = 0.4697, Train Accuracy = 86.81%\n","Epoch 1: Test Loss = 0.4114, Test Accuracy = 87.30%\n","Epoch 2: Train Loss = 0.3739, Train Accuracy = 88.82%\n","Epoch 2: Test Loss = 0.3618, Test Accuracy = 89.00%\n","LayerConductance\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.50\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerIntegratedGradients\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.50\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerDeepLift\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.50\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","Epoch 0: Train Loss = 1.2669, Train Accuracy = 69.41%\n","Epoch 0: Test Loss = 0.6028, Test Accuracy = 83.10%\n","Epoch 1: Train Loss = 0.4679, Train Accuracy = 87.02%\n","Epoch 1: Test Loss = 0.4076, Test Accuracy = 87.40%\n","Epoch 2: Train Loss = 0.3710, Train Accuracy = 89.03%\n","Epoch 2: Test Loss = 0.3533, Test Accuracy = 89.30%\n","LayerConductance\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerIntegratedGradients\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerDeepLift\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","Epoch 0: Train Loss = 1.2585, Train Accuracy = 69.52%\n","Epoch 0: Test Loss = 0.5998, Test Accuracy = 83.20%\n","Epoch 1: Train Loss = 0.4639, Train Accuracy = 87.01%\n","Epoch 1: Test Loss = 0.4027, Test Accuracy = 87.50%\n","Epoch 2: Train Loss = 0.3626, Train Accuracy = 89.30%\n","Epoch 2: Test Loss = 0.3469, Test Accuracy = 89.20%\n","LayerConductance\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.02\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.48\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerIntegratedGradients\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.02\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.48\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerDeepLift\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.02\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.48\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","Epoch 0: Train Loss = 1.2697, Train Accuracy = 69.00%\n","Epoch 0: Test Loss = 0.6059, Test Accuracy = 83.20%\n","Epoch 1: Train Loss = 0.4671, Train Accuracy = 86.89%\n","Epoch 1: Test Loss = 0.4229, Test Accuracy = 86.50%\n","Epoch 2: Train Loss = 0.3678, Train Accuracy = 89.00%\n","Epoch 2: Test Loss = 0.3501, Test Accuracy = 89.70%\n","LayerConductance\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerIntegratedGradients\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerDeepLift\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","Epoch 0: Train Loss = 1.2779, Train Accuracy = 69.98%\n","Epoch 0: Test Loss = 0.6005, Test Accuracy = 83.10%\n","Epoch 1: Train Loss = 0.4728, Train Accuracy = 86.83%\n","Epoch 1: Test Loss = 0.4132, Test Accuracy = 87.60%\n","Epoch 2: Train Loss = 0.3720, Train Accuracy = 89.08%\n","Epoch 2: Test Loss = 0.3531, Test Accuracy = 89.10%\n","LayerConductance\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerIntegratedGradients\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n","LayerDeepLift\n","conv1x1\n","conv1x1_3x3\n","conv1x1_5x5\n","pool\n","fc\n","0.01\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.00\n","torch.Size([128, 16, 28, 28])\n","\n","0.49\n","torch.Size([128, 1, 28, 28])\n","\n","0.50\n","torch.Size([128, 10])\n","\n","\n","\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}