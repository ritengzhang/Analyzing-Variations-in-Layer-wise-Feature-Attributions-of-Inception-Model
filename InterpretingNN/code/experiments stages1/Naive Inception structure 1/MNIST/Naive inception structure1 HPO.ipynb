{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BwxjuWX_Z-hD"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"id":"Z4TuItTJELaX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v1WCo6P2V9Rj"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from captum.attr import LayerIntegratedGradients\n","from captum.attr import LayerConductance\n","from captum.attr import LayerDeepLift\n","import pickle\n","import os\n","import csv"]},{"cell_type":"code","source":["method_names = [\"LayerConductance\", \"LayerIntegratedGradients\", \"LayerDeepLift\"]\n","train_size=30000\n","test_size=1000"],"metadata":{"id":"iGIJ829bgvE-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model structure defination"],"metadata":{"id":"3PEfJs6TqkYl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBL4NJNdWZlo"},"outputs":[],"source":["class NaiveInception(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(NaiveInception, self).__init__()\n","\n","        self.conv1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n","        self.conv1x1_3x3 = nn.Sequential(\n","            nn.Conv2d(in_channels, 8, kernel_size=1),\n","            nn.Conv2d(8, 16, kernel_size=3, padding=1)\n","        )\n","        self.conv1x1_5x5 = nn.Sequential(\n","            nn.Conv2d(in_channels, 8, kernel_size=1),\n","            nn.Conv2d(8, 16, kernel_size=5, padding=2)\n","        )\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(38416, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, num_classes)  # Number of output classes\n","        )\n","\n","    def forward(self, x):\n","        x1 = self.conv1x1(x)\n","        x2 = self.conv1x1_3x3(x)\n","        x3 = self.conv1x1_5x5(x)\n","        x4 = self.pool(x)\n","        x = torch.cat((x1, x2, x3, x4), dim=1)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"markdown","source":["# FLOP Count"],"metadata":{"id":"AUpAtp4cqFF3"}},{"cell_type":"markdown","source":["get size of the input data"],"metadata":{"id":"7eOMNTfeVs6F"}},{"cell_type":"code","source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_subset = datasets.MNIST('.', train=True, download=True, transform=transform)\n","test_subset = datasets.MNIST('.', train=False, download=True, transform=transform)\n","\n","# Define the size of the random subsets\n","train_indices = torch.randperm(len(train_subset))[:train_size]\n","test_indices = torch.randperm(len(test_subset))[:test_size]\n","\n","train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n","test_loader = torch.utils.data.DataLoader(test_subset, batch_size=16, sampler=torch.utils.data.SubsetRandomSampler(test_indices))\n","for input_data in train_loader:\n","  print(input_data[0].size())\n","  break"],"metadata":{"id":"AuDsatyfVb7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["calculate flops for each layer"],"metadata":{"id":"DC5LEd1ZVuyU"}},{"cell_type":"code","source":["def count_flops(model, input_tensor):\n","    flops = {}  # Use a dictionary to store FLOPs for each layer\n","    hooks = []  # We'll use hooks to count FLOPs for each layer\n","\n","    def hook_fn(module, input, output):\n","        if isinstance(module, nn.Conv2d):\n","            # Calculate FLOPs for Conv2d layer\n","            input_shape = input[0].shape\n","            kernel_shape = module.weight.shape\n","            flops[module] = int(input_shape[1] * kernel_shape[2] * kernel_shape[3] * kernel_shape[0] * input_shape[2] * input_shape[3] / module.groups)\n","\n","    def register_hooks(module):\n","        # Register hooks for all Conv2d layers\n","        for layer in module.children():\n","            if isinstance(layer, nn.Conv2d):\n","                hook = layer.register_forward_hook(hook_fn)\n","                hooks.append(hook)\n","            elif isinstance(layer, nn.Sequential):\n","                register_hooks(layer)\n","\n","    # Register hooks for all layers in the model\n","    register_hooks(model)\n","\n","    # Run input through the model\n","    with torch.no_grad():\n","        model(input_tensor)\n","\n","    # Remove the hooks\n","    for hook in hooks:\n","        hook.remove()\n","\n","    return flops\n","\n","# Example usage:\n","input_tensor = torch.randn(1, 1, 28, 28)  # Example input tensor with shape (batch_size, channels, height, width)\n","model = NaiveInception(in_channels=1, num_classes=10)  # Create an instance of the NaiveInception model\n","flops = count_flops(model, input_tensor)\n","\n","# Print FLOPs for each layer\n","for layer, flop_count in flops.items():\n","    print(f\"{layer.__class__.__name__}: {flop_count} FLOPs\")\n"],"metadata":{"id":"ilIIYRj1UiWo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train all models and record attributions"],"metadata":{"id":"XXZkt8qbqf0O"}},{"cell_type":"markdown","source":["get model"],"metadata":{"id":"4PsqoM7prXA_"}},{"cell_type":"code","source":["# Create and train the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Create an instance of the Inception-like 3-stack model\n","in_channels = 1  # Input channels (e.g., for RGB images)\n","num_classes = 10  # Number of classes in your classification task\n","model = NaiveInception(in_channels, num_classes).to(device)"],"metadata":{"id":"cz-Mh59v_REL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["get train process"],"metadata":{"id":"QzIPgKX7rbum"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwGcAozxTBPX"},"outputs":[],"source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_subset = datasets.MNIST('.', train=True, download=True, transform=transform)\n","test_subset = datasets.MNIST('.', train=False, download=True, transform=transform)\n","\n","# Define the size of the random subsets\n","train_indices = torch.randperm(len(train_subset))[:train_size]\n","test_indices = torch.randperm(len(test_subset))[:test_size]\n","\n","train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n","test_loader = torch.utils.data.DataLoader(test_subset, batch_size=16, sampler=torch.utils.data.SubsetRandomSampler(test_indices))\n","\n","# Create and train the model on the GPU\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n"]},{"cell_type":"markdown","source":["train and eval function"],"metadata":{"id":"tgrdsZx2reqY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2MutHefenjn"},"outputs":[],"source":["def train(epoch):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = output.max(1)\n","        total += target.size(0)\n","        correct += predicted.eq(target).sum().item()\n","\n","    train_accuracy = 100. * correct / total\n","    print(f\"Epoch {epoch}: Train Loss = {train_loss / len(train_loader):.4f}, Train Accuracy = {train_accuracy:.2f}%\")\n","\n","\n","def test(epoch):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            test_loss += loss.item()\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","    test_accuracy = 100. * correct / total\n","    print(f\"Epoch {epoch}: Test Loss = {test_loss / len(test_loader):.4f}, Test Accuracy = {test_accuracy:.2f}%\")"]},{"cell_type":"markdown","source":["functions for calculate attribution"],"metadata":{"id":"oaOM2lSHr84W"}},{"cell_type":"code","source":["def calculate_attribution_one_layer(model, layer, input_data, target_class, method):\n","    methods = {\"LayerConductance\": LayerConductance, \"LayerIntegratedGradients\": LayerIntegratedGradients, \"LayerDeepLift\": LayerDeepLift}\n","    using_function = methods[method](model, layer)\n","    attribution = using_function.attribute(input_data, target=target_class)\n","\n","    return attribution"],"metadata":{"id":"bqNNcDVNEATu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_all_attributions_one_input(model, input_data, target_class, method):\n","    all_attributions = {}\n","    for name, layer in model.named_children():\n","      print(name)\n","      all_attributions[layer] = []\n","      layer_attributions=calculate_attribution_one_layer(model, layer, input_data, target_class, method)\n","      all_attributions[layer]=layer_attributions\n","    return all_attributions"],"metadata":{"id":"5HyQeJvGEBve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_and_save_attributions(model, model_index, sample_input, target_class, method_names):\n","    # Ensure sample_input has gradients\n","    sample_input.requires_grad_()\n","\n","    # Set device for model and input tensor\n","    device = torch.device(\"cpu\")\n","    sample_input = sample_input.to(device)\n","    model.to(device)\n","\n","\n","    # Calculate and print importance scores for each layer and neuron\n","    for method in method_names:\n","        print(method)\n","        attributions = get_all_attributions_one_input(model, sample_input, target_class, method=method)\n","        attribution_sum = 0\n","\n","        for i in attributions:\n","            attribution_sum = attribution_sum + attributions[i].sum().item()\n","\n","        for i in attributions:\n","            a = attributions[i].sum().item() / attribution_sum\n","            formatted_number = f\"{a:.2f}\"\n","            print(formatted_number)\n","            print(attributions[i].shape)\n","            print()\n","\n","        print(\"\\n\\n\")\n"],"metadata":{"id":"P59jSsIhkWtk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["train, save, and recored attribution info of models"],"metadata":{"id":"qk1DF9SfsG--"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDNOPlv8fyjn"},"outputs":[],"source":["for i in range(5):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    in_channels = 1  # Input channels (e.g., for RGB images)\n","    num_classes = 10  # Number of classes in your classification task\n","\n","    model = NaiveInception(in_channels, num_classes).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=0.01)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    for epoch in range(3):\n","      train(epoch)\n","      test(epoch)\n","    model_index=\"test\"+str(i)\n","    sample_input, target_class=None, None\n","    for batch_idx, (data, target) in enumerate(test_loader):\n","      sample_input, target_class = data, target\n","      break\n","    calculate_and_save_attributions(model, model_index, sample_input, target_class, method_names)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}