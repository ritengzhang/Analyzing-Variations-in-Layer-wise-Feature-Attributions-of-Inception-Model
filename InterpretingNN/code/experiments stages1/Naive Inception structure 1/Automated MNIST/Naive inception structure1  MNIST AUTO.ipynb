{"cells":[{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":728,"status":"ok","timestamp":1699978251936,"user":{"displayName":"张日腾","userId":"15474554812672166345"},"user_tz":300},"id":"BwxjuWX_Z-hD"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install captum\n","!pip install fvcore"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4TuItTJELaX","executionInfo":{"status":"ok","timestamp":1699978259837,"user_tz":300,"elapsed":7108,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"564d5dc2-dc58-41a4-9656-b83254148115"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.44.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n","Requirement already satisfied: fvcore in /usr/local/lib/python3.10/dist-packages (0.1.5.post20221221)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.23.5)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.1.8)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.3.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n","Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.1.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.5.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (2.8.2)\n"]}]},{"cell_type":"code","execution_count":24,"metadata":{"id":"v1WCo6P2V9Rj","executionInfo":{"status":"ok","timestamp":1699978259837,"user_tz":300,"elapsed":6,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from captum.attr import visualization as viz\n","from fvcore.nn import FlopCountAnalysis, flop_count_table\n","from captum.attr import IntegratedGradients, LayerConductance, DeepLift, LayerDeepLift,LayerIntegratedGradients\n","import itertools\n","import pandas as pd\n","import os\n","import random\n","import numpy as np\n","from itertools import product\n","from torch.utils.data import SequentialSampler, RandomSampler\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["method_names = [\"LayerIntegratedGradients\", \"LayerDeepLift\"]\n","INPUT_SHAPE= (1, 1, 28, 28)\n","Training_Device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","Feature_Attribution_Device = torch.device(\"cpu\")\n","NUM_EPOCHS=3\n","NUM_CLASSES=10\n","IN_CHANNELS=1"],"metadata":{"id":"iGIJ829bgvE-","executionInfo":{"status":"ok","timestamp":1699978259838,"user_tz":300,"elapsed":6,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["# Model structure defination"],"metadata":{"id":"3PEfJs6TqkYl"}},{"cell_type":"code","source":["class Inception(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super(Inception, self).__init__()\n","\n","        self.conv1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n","        self.conv1x1_3x3 = nn.Sequential(\n","            nn.Conv2d(in_channels, 8, kernel_size=1),\n","            nn.Conv2d(8, 16, kernel_size=3, padding=1)\n","        )\n","        self.conv1x1_5x5 = nn.Sequential(\n","            nn.Conv2d(in_channels, 8, kernel_size=1),\n","            nn.Conv2d(8, 16, kernel_size=5, padding=2)\n","        )\n","        self.pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(38416, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, num_classes)  # Number of output classes\n","        )\n","\n","    def forward(self, x):\n","        x1 = self.conv1x1(x)\n","        x2 = self.conv1x1_3x3(x)\n","        x3 = self.conv1x1_5x5(x)\n","        x4 = self.pool(x)\n","        x = torch.cat((x1, x2, x3, x4), dim=1)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"vgBlOPyofP-I","executionInfo":{"status":"ok","timestamp":1699978259838,"user_tz":300,"elapsed":6,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["# Get dataset"],"metadata":{"id":"qKlgVcuqU1UE"}},{"cell_type":"code","source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('.', train=False, download=True, transform=transform)"],"metadata":{"id":"m8x6hFdGU4QQ","executionInfo":{"status":"ok","timestamp":1699978259838,"user_tz":300,"elapsed":6,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["# FLOP Count"],"metadata":{"id":"AUpAtp4cqFF3"}},{"cell_type":"code","source":["def count_flops(model, input_size):\n","    inputs = torch.randn(input_size)\n","    flops = FlopCountAnalysis(model, inputs)\n","    return flop_count_table(flops)\n","\n","inception_model = Inception(1, 10)\n","# Assuming the input size for CIFAR-10 (batch size, channels, height, width)\n","input_size = (1, 1, 28, 28)\n","flops_table = count_flops(inception_model, input_size)\n","print(flops_table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ilIIYRj1UiWo","executionInfo":{"status":"ok","timestamp":1699978259838,"user_tz":300,"elapsed":5,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"88339d7b-31de-4dff-d517-87c8acec1dbc"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["| module                  | #parameters or shape   | #flops   |\n","|:------------------------|:-----------------------|:---------|\n","| model                   | 9.842M                 | 13.274M  |\n","|  conv1x1                |  32                    |  12.544K |\n","|   conv1x1.weight        |   (16, 1, 1, 1)        |          |\n","|   conv1x1.bias          |   (16,)                |          |\n","|  conv1x1_3x3            |  1.184K                |  0.909M  |\n","|   conv1x1_3x3.0         |   16                   |   6.272K |\n","|    conv1x1_3x3.0.weight |    (8, 1, 1, 1)        |          |\n","|    conv1x1_3x3.0.bias   |    (8,)                |          |\n","|   conv1x1_3x3.1         |   1.168K               |   0.903M |\n","|    conv1x1_3x3.1.weight |    (16, 8, 3, 3)       |          |\n","|    conv1x1_3x3.1.bias   |    (16,)               |          |\n","|  conv1x1_5x5            |  3.232K                |  2.515M  |\n","|   conv1x1_5x5.0         |   16                   |   6.272K |\n","|    conv1x1_5x5.0.weight |    (8, 1, 1, 1)        |          |\n","|    conv1x1_5x5.0.bias   |    (8,)                |          |\n","|   conv1x1_5x5.1         |   3.216K               |   2.509M |\n","|    conv1x1_5x5.1.weight |    (16, 8, 5, 5)       |          |\n","|    conv1x1_5x5.1.bias   |    (16,)               |          |\n","|  fc                     |  9.837M                |  9.837M  |\n","|   fc.0                  |   9.835M               |   9.834M |\n","|    fc.0.weight          |    (256, 38416)        |          |\n","|    fc.0.bias            |    (256,)              |          |\n","|   fc.2                  |   2.57K                |   2.56K  |\n","|    fc.2.weight          |    (10, 256)           |          |\n","|    fc.2.bias            |    (10,)               |          |\n"]}]},{"cell_type":"markdown","source":["# Train and attribution functions"],"metadata":{"id":"XXZkt8qbqf0O"}},{"cell_type":"markdown","source":["train and eval function"],"metadata":{"id":"tgrdsZx2reqY"}},{"cell_type":"code","execution_count":29,"metadata":{"id":"J2MutHefenjn","executionInfo":{"status":"ok","timestamp":1699978259838,"user_tz":300,"elapsed":4,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"outputs":[],"source":["def train(epoch, model, train_loader, optimizer, criterion, device):\n","    model.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = output.max(1)\n","        total += target.size(0)\n","        correct += predicted.eq(target).sum().item()\n","\n","    train_accuracy = 100. * correct / total\n","    print(f\"Epoch {epoch}: Train Loss = {train_loss / len(train_loader):.4f}, Train Accuracy = {train_accuracy:.2f}%\")\n","\n","    return train_accuracy\n","\n","def test(epoch, model, test_loader, criterion, device):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            test_loss += loss.item()\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","    test_accuracy = 100. * correct / total\n","    print(f\"Epoch {epoch}: Test Loss = {test_loss / len(test_loader):.4f}, Test Accuracy = {test_accuracy:.2f}%\")\n","\n","    return test_accuracy\n"]},{"cell_type":"markdown","source":["functions for calculate attribution"],"metadata":{"id":"oaOM2lSHr84W"}},{"cell_type":"code","source":["def print_ig(test_loader, model, device):\n","    # Move the model to the device (CPU or CUDA)\n","    model.to(device)\n","\n","    # Ensure the model is in evaluation mode\n","    model.eval()\n","\n","    # Get a single batch from the test loader\n","    inputs, target_class = next(iter(test_loader))\n","    inputs = inputs.to(device)\n","\n","    ig_attributions = {}\n","\n","    # Iterate through each named module and compute attributions for Conv2d layers with learnable parameters\n","    for layer_name, layer_module in model.named_modules():\n","        # Check if the layer is a Conv2d layer with learnable parameters\n","        if isinstance(layer_module, nn.Conv2d) and any(p.requires_grad for p in layer_module.parameters(recurse=False)):\n","            # Initialize LayerIntegratedGradients for the layer\n","            lig = LayerIntegratedGradients(model, layer_module)\n","\n","            # Compute the attributions for the current layer\n","            try:\n","                attributions = lig.attribute(inputs, target=target_class.to(device))\n","            except Exception as e:\n","                print(f\"Error computing attributions for layer {layer_name}: {e}\")\n","                continue\n","\n","            # Print out the attributions for the current layer\n","            print(f'Layer: {layer_name}')\n","            print(f'Attribution: {attributions.cpu().detach().numpy().sum()}')\n","\n","            # Store the sum of attributions in the dictionary\n","            ig_attributions[layer_name] = attributions.cpu().detach().numpy().sum()\n","\n","            # Free up memory\n","            del attributions, lig\n","\n","    return ig_attributions\n","\n","# Usage example:\n","# ig_attributions = print_ig(test_loader, model, device)\n"],"metadata":{"id":"80MC-kmyoso7","executionInfo":{"status":"ok","timestamp":1699978259838,"user_tz":300,"elapsed":4,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def print_deeplift(test_loader, model, device):\n","    # Move the model to the specified device and set it to evaluation mode\n","    model.to(device).eval()\n","\n","    # Get a batch of data from the loader\n","    inputs, target_class = next(iter(test_loader))\n","    inputs, target_class = inputs.to(device), target_class.to(device)\n","\n","    dl_attributions = {}\n","\n","    # Now compute the attributions for Conv2d layers\n","    for layer_name, layer_module in model.named_modules():\n","        # Skip the whole model's container and focus on Conv2d layers with learnable parameters\n","        if isinstance(layer_module, nn.Conv2d) and any(p.requires_grad for p in layer_module.parameters(recurse=False)):\n","            # Initialize LayerDeepLift with the current layer\n","            ldl = LayerDeepLift(model, layer_module)\n","\n","            # Compute the attributions for the current layer\n","            '''try:\n","                attributions_ldl = ldl.attribute(inputs, target=target_class.to(device))\n","            except Exception as e:\n","                print(f\"Error computing attributions for layer {layer_name}: {e}\")\n","                continue'''\n","            attributions_ldl = ldl.attribute(inputs, target=target_class.to(device))\n","\n","\n","            # Print out the attributions for the current layer\n","            print(f'Layer: {layer_name}')\n","            print(attributions_ldl.cpu().data.numpy().sum())\n","\n","            dl_attributions[layer_name] = attributions_ldl.cpu().data.numpy().sum()\n","\n","            del attributions_ldl, ldl\n","\n","    return dl_attributions\n","\n","# Usage example:\n","# dl_attributions = print_deeplift(test_loader, model, device)\n"],"metadata":{"id":"ezNUU3zqX0MS","executionInfo":{"status":"ok","timestamp":1699978259838,"user_tz":300,"elapsed":4,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# Possible Hyperparameter grid search creation"],"metadata":{"id":"zd0sJ_PUP-PD"}},{"cell_type":"markdown","source":["in hyperparams_list_dict, each hyperparameter has corresponding possible choices as a list, during experiment, given hyperparams sequence, location each hyperperameter's location using hyperparameter encoding function to convert strings or classes back into their index in hyperparams_list_dict"],"metadata":{"id":"yvwYBb6Fkbun"}},{"cell_type":"code","source":["hyperparams_list_dict = {\n","    'initial_lr': [],\n","    'optimizer': torch.optim.Adam,  # Example optimizer\n","    'criterion': torch.nn.CrossEntropyLoss(),\n","    'train_data_used': 0.8,\n","    'train_set_shuffle': True,\n","    'train_batch_size': 64\n","}"],"metadata":{"id":"l3gZHl9OkOWp","executionInfo":{"status":"ok","timestamp":1699978260083,"user_tz":300,"elapsed":249,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def generate_hyperparameter_combinations(hyperparams):\n","    \"\"\"\n","    Generate a sequence of hyperparameter combinations.\n","\n","    :param hyperparams: A dictionary where keys are the names of hyperparameters,\n","                        and values are lists of possible choices for each hyperparameter.\n","    :return: A list of dictionaries, each representing a unique combination of hyperparameters.\n","    \"\"\"\n","    # Extract the hyperparameter names and their corresponding choices\n","    keys, values = zip(*hyperparams.items())\n","\n","    # Generate all possible combinations of hyperparameter values\n","    all_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n","\n","    return all_combinations\n","\n","# Example Usage\n","hyperparams = {\n","    'initial_lr': [0.001],\n","    'optimizer': [torch.optim.Adam], # Example optimizer\n","    'criterion': [torch.nn.CrossEntropyLoss()],\n","    'train_data_used': [0.8],\n","    'train_set_shuffle': [True],\n","    'train_batch_size': [64]\n","\n","}\n","\n","combinations = generate_hyperparameter_combinations(hyperparams)\n","for combo in combinations:\n","    print(combo)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPVBxkV0QKcT","executionInfo":{"status":"ok","timestamp":1699978260083,"user_tz":300,"elapsed":2,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"4e2dc862-dd01-4b79-b6fa-2c2f422492fe"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["{'initial_lr': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>, 'criterion': CrossEntropyLoss(), 'train_data_used': 0.8, 'train_set_shuffle': True, 'train_batch_size': 64}\n"]}]},{"cell_type":"markdown","source":["# Automated Experiments"],"metadata":{"id":"5MTBSIzdrQyp"}},{"cell_type":"code","source":["def get_data_loader(hyperparams, train_dataset, test_dataset):\n","  shuffle = hyperparams['train_set_shuffle']\n","  train_batch_size = hyperparams[\"train_batch_size\"]\n","\n","  train_data_used_num = int(len(train_dataset) * hyperparams[\"train_data_used\"])\n","  train_indices = torch.randperm(len(train_dataset))[:train_data_used_num]\n","\n","  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=shuffle)\n","  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n","  return train_loader, test_loader"],"metadata":{"id":"a9EHrusQgpIN","executionInfo":{"status":"ok","timestamp":1699978260083,"user_tz":300,"elapsed":1,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def run_experiments(hyperparams, train_loader, test_loader, num_epochs=NUM_EPOCHS, num_classes=NUM_CLASSES, in_channels=IN_CHANNELS,):\n","    # Initialize model\n","    model = Inception(in_channels, num_classes).to(Training_Device)  # Assuming Inception is defined elsewhere\n","\n","    # Use the optimizer from hyperparameters\n","    optimizer = hyperparams['optimizer'](model.parameters(), lr=hyperparams['initial_lr'])\n","    criterion = hyperparams['criterion']\n","\n","    train_accuracy = {}\n","    test_accuracy = {}\n","\n","    for epoch in range(num_epochs):\n","            # Assuming train and test functions are defined elsewhere\n","            train_acc = train(epoch, model, train_loader, optimizer, criterion, Training_Device)\n","            test_acc = test(epoch, model, test_loader, criterion, Training_Device)\n","\n","            train_accuracy[\"train accuracy epoch\"+str(epoch)] = train_acc\n","            test_accuracy[\"test accuracy epoch\"+str(epoch)] = test_acc\n","\n","\n","\n","\n","    dl_attributions = print_deeplift(test_loader, model, Feature_Attribution_Device)\n","    print(\"\\n\")\n","\n","    ig_attributions = print_ig(test_loader, model, Feature_Attribution_Device)\n","    print(\"\\n\")\n","    return dl_attributions, ig_attributions, train_accuracy, test_accuracy\n","\n","# Example Usage\n","hyperparams = {\n","    'initial_lr': 0.001,\n","    'optimizer': torch.optim.Adam,  # Example optimizer\n","    'criterion': torch.nn.CrossEntropyLoss(),\n","    'train_data_used': 0.8,\n","    'train_set_shuffle': True,\n","    'train_batch_size': 64\n","\n","}\n","\n","train_loader, test_loader = get_data_loader(hyperparams, train_dataset, test_dataset)\n","print(run_experiments(num_epochs=0, hyperparams=hyperparams, train_loader=train_loader, test_loader=test_loader))"],"metadata":{"id":"vQubiqe3rTxi","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1699978264557,"user_tz":300,"elapsed":216,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"bf2a0df1-2d44-4d5d-e11d-ca16884cba91"},"execution_count":35,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-21be2ac92bd6>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-35-21be2ac92bd6>\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(hyperparams, train_loader, test_loader, num_epochs, num_classes, in_channels)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdl_attributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_deeplift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeature_Attribution_Device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-31-780439918116>\u001b[0m in \u001b[0;36mprint_deeplift\u001b[0;34m(test_loader, model, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error computing attributions for layer {layer_name}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 continue'''\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mattributions_ldl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/layer/layer_deep_lift.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, return_convergence_delta, attribute_to_layer_input, custom_attribution_func)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_sub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             gradients, attrs = compute_layer_gradients_and_eval(\n\u001b[0m\u001b[1;32m    326\u001b[0m                 \u001b[0mwrapped_forward_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_layer_gradients_and_eval\u001b[0;34m(forward_fn, layer, inputs, target_ind, additional_forward_args, gradient_neuron_selector, device_ids, attribute_to_layer_input, output_fn)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# saved_layer is a dictionary mapping device to a tuple of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# layer evaluations on that device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         saved_layer, output = _forward_layer_distributed_eval(\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36m_forward_layer_distributed_eval\u001b[0;34m(forward_fn, inputs, layer, target_ind, additional_forward_args, attribute_to_layer_input, forward_hook_with_return, require_layer_grads)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0msingle_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 )\n\u001b[0;32m--> 294\u001b[0;31m         output = _run_forward(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mforward_func_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_func_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_select_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/attr/_core/deep_lift.py\u001b[0m in \u001b[0;36mforward_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    367\u001b[0m     ) -> Callable:\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             model_out = _run_forward(\n\u001b[0m\u001b[1;32m    370\u001b[0m                 \u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0madditional_forward_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_additional_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     output = forward_func(\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m                 for hook_id, hook in (\n","\u001b[0;32m<ipython-input-26-973be7f29d10>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1x1_3x3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1x1_5x5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                                 )\n\u001b[1;32m   1556\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                         \u001b[0margs_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0margs_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36mpre_hook\u001b[0;34m(module, inp)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             ), \"Backward hooks not supported for module with >1 input\"\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mregister_hook\u001b[0;34m(self, hook)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    533\u001b[0m                 \u001b[0;34m\"cannot register a hook on a tensor that doesn't require gradient\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             )\n","\u001b[0;31mRuntimeError\u001b[0m: cannot register a hook on a tensor that doesn't require gradient"]}]},{"cell_type":"markdown","source":["# Functions for saving attribution"],"metadata":{"id":"c9bUANDDP2ck"}},{"cell_type":"code","source":["def run_experiments_and_save(num_epochs, hyperparams_combinations, train_dataset, test_dataset, csv_file):\n","    \"\"\"\n","    Run experiments for each combination of hyperparameters, get feature layer attributions for DeepLift and Integrated Gradients,\n","    save the results to a CSV file, and skip any combinations that have already been run.\n","\n","    :param hyperparams_combinations: List of dictionaries with hyperparameter combinations.\n","    :param attribution_function: Function to compute feature layer attribution.\n","    :param csv_file: Path to the CSV file for saving results.\n","    \"\"\"\n","\n","    # Check if the CSV file exists and load existing data\n","    if os.path.exists(csv_file):\n","        existing_data = pd.read_csv(csv_file)\n","    else:\n","        existing_data = pd.DataFrame()\n","\n","    for combo in hyperparams_combinations:\n","        for i in range(10):  # For each run index\n","            for method in ['deeplift', 'integrated_gradients']:  # For each method\n","                # Prepare data for checking if it's already processed\n","                combo_check = combo.copy()\n","                combo_check['method'] = method\n","                combo_check['run'] = i\n","\n","                # Check if this specific combination is already processed\n","                if not existing_data.empty and (existing_data[list(combo_check.keys())] == list(combo_check.values())).all(axis=1).any():\n","                    continue  # Skip if combination is already processed\n","\n","                # Set seed for reproducibility\n","                random.seed(i)\n","                np.random.seed(i)\n","                torch.manual_seed(i)\n","                if torch.cuda.is_available():\n","                    torch.cuda.manual_seed_all(i)\n","\n","                train_loader, test_loader = get_data_loader(hyperparams, train_dataset, test_dataset)\n","\n","                # Initialize model\n","                # Compute attributions\n","                attr = run_experiments(hyperparams=hyperparams, train_loader=train_loader, test_loader=test_loader)\n","\n","                # Prepare data for saving\n","                combo_results = combo.copy()\n","                combo_results.update(attr)\n","                combo_results['method'] = method\n","                combo_results['run'] = i\n","\n","                # Append results to the existing data\n","                existing_data = existing_data.append(combo_results, ignore_index=True)\n","\n","    # Save the data to CSV\n","    existing_data.to_csv(csv_file, index=False)\n","\n","# Example Usage\n","hyperparams_combinations = [dict(zip(hyperparams, v)) for v in product(*hyperparams.values())]"],"metadata":{"id":"lEeBBBoFQJ9j","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"error","timestamp":1699977846097,"user_tz":300,"elapsed":12,"user":{"displayName":"张日腾","userId":"15474554812672166345"}},"outputId":"0786f7cb-5225-4318-eb47-26619a66760f"},"execution_count":15,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-413b89985bd2>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Example Usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mhyperparams_combinations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"]}]},{"cell_type":"markdown","source":["# Experiments"],"metadata":{"id":"F5HnBUgS2fAG"}},{"cell_type":"code","source":["run_experiments(num_epochs=5, num_classes=10, in_channels=3, num_experiments=10, hyperparams=hyperparams, train_dataset=train_dataset, test_dataset=test_dataset)"],"metadata":{"id":"BlcVe1STrPEJ","executionInfo":{"status":"aborted","timestamp":1699977846097,"user_tz":300,"elapsed":10,"user":{"displayName":"张日腾","userId":"15474554812672166345"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}